{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this workshop, we will go through the steps of training, debugging, deploying and monitoring a **network traffic classification model**.\n",
    "\n",
    "For training our model we will be using datasets <a href=\"https://registry.opendata.aws/cse-cic-ids2018/\">CSE-CIC-IDS2018</a> by CIC and ISCX which are used for security testing and malware prevention.\n",
    "These datasets include a huge amount of raw network traffic logs, plus pre-processed data where network connections have been reconstructed and  relevant features have been extracted using CICFlowMeter, a tool that outputs network connection features as CSV files. Each record is classified as benign traffic, or it can be malicious traffic, with a total number of 15 classes.\n",
    "\n",
    "Starting from this featurized dataset, we have executed additional pre-processing for the purpose of this lab:\n",
    "<ul>\n",
    "    <li>Encoded class labels</li>\n",
    "    <li>Replaced invalid string attribute values generated by CICFlowMeter (e.g. inf and Infinity)</li>\n",
    "    <li>Executed one hot encoding of discrete attributes</li>\n",
    "    <li>Remove invalid headers logged multiple times in the same CSV file</li>\n",
    "    <li>Reduced the size of the featurized dataset to ~1.3GB (from ~6.3GB) to speed-up training, while making sure that all classes are well represented</li>\n",
    "    <li>Executed stratified random split of the dataset into training (80%) and validation (20%) sets</li>\n",
    "</ul>\n",
    "\n",
    "Class are represented and have been encoded as follows (train + validation):\n",
    "\n",
    "\n",
    "| Label                    | Encoded | N. records |\n",
    "|:-------------------------|:-------:|-----------:|\n",
    "| Benign                   |    0    |    1000000 |\n",
    "| Bot                      |    1    |     200000 |\n",
    "| DoS attacks-GoldenEye    |    2    |      40000 |\n",
    "| DoS attacks-Slowloris    |    3    |      10000 |\n",
    "| DDoS attacks-LOIC-HTTP   |    4    |     300000 |\n",
    "| Infilteration            |    5    |     150000 |\n",
    "| DDOS attack-LOIC-UDP     |    6    |       1730 |\n",
    "| DDOS attack-HOIC         |    7    |     300000 |\n",
    "| Brute Force -Web         |    8    |        611 |\n",
    "| Brute Force -XSS         |    9    |        230 |\n",
    "| SQL Injection            |   10    |         87 |\n",
    "| DoS attacks-SlowHTTPTest |   11    |     100000 |\n",
    "| DoS attacks-Hulk         |   12    |     250000 |\n",
    "| FTP-BruteForce           |   13    |     150000 |\n",
    "| SSH-Bruteforce           |   14    |     150000 |       \n",
    "\n",
    "The final pre-processed dataset has been saved to a public Amazon S3 bucket for your convenience, and will represent the inputs to the training processes.\n",
    "\n",
    "### Let's get started!\n",
    "\n",
    "First, we set some variables, including the AWS region we are working in, the IAM (Identity and Access Management) execution role of the notebook instance and the Amazon S3 bucket where we will store data, models, outputs, etc. We will use the Amazon SageMaker default bucket for the selected AWS region, and then define a key prefix to make sure all objects have share the same prefix for easier discoverability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\n",
      "sagemaker-us-east-1-835319576252\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "prefix = 'aim362'\n",
    "os.environ[\"AWS_REGION\"] = region\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can copy the dataset from the public Amazon S3 bucket to the Amazon SageMaker default bucket used in this workshop. To do this, we will leverage on the AWS Python SDK (boto3) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying aim362/data/train/0.part ...\n",
      "Copying aim362/data/train/1.part ...\n",
      "Copying aim362/data/train/2.part ...\n",
      "Copying aim362/data/train/3.part ...\n",
      "Copying aim362/data/train/4.part ...\n",
      "Copying aim362/data/train/5.part ...\n",
      "Copying aim362/data/train/6.part ...\n",
      "Copying aim362/data/train/7.part ...\n",
      "Copying aim362/data/train/8.part ...\n",
      "Copying aim362/data/train/9.part ...\n",
      "Copying aim362/data/val/0.part ...\n",
      "Copying aim362/data/val/1.part ...\n",
      "Copying aim362/data/val/2.part ...\n",
      "Copying aim362/data/val/3.part ...\n",
      "Copying aim362/data/val/4.part ...\n",
      "Copying aim362/data/val/5.part ...\n",
      "Copying aim362/data/val/6.part ...\n",
      "Copying aim362/data/val/7.part ...\n",
      "Copying aim362/data/val/8.part ...\n",
      "Copying aim362/data/val/9.part ...\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "source_bucket_name = \"endtoendmlapp\"\n",
    "source_bucket_prefix = \"aim362/data/\"\n",
    "source_bucket = s3.Bucket(source_bucket_name)\n",
    "\n",
    "for s3_object in source_bucket.objects.filter(Prefix=source_bucket_prefix):\n",
    "    copy_source = {\n",
    "        'Bucket': source_bucket_name,\n",
    "        'Key': s3_object.key\n",
    "    }\n",
    "    print('Copying {0} ...'.format(s3_object.key))\n",
    "    s3.Bucket(bucket_name).copy(copy_source, s3_object.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download some of the data to the notebook to quickly explore the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 's3://' + bucket_name + '/' + prefix + '/data/train/0.part'\n",
    "val_file_path = 's3://' + bucket_name + '/' + prefix + '/data/val/0.part'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-835319576252/aim362/data/train/0.part to data/train/0.part\n",
      "download: s3://sagemaker-us-east-1-835319576252/aim362/data/val/0.part to data/val/0.part\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data/train/ data/val/\n",
    "!aws s3 cp {train_file_path} data/train/\n",
    "!aws s3 cp {val_file_path} data/val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>Bwd Pkt Len Min</th>\n",
       "      <th>Bwd Pkt Len Mean</th>\n",
       "      <th>Bwd Pkt Len Std</th>\n",
       "      <th>Flow Byts/s</th>\n",
       "      <th>Flow Pkts/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Tot</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Tot</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Fwd PSH Flags</th>\n",
       "      <th>Bwd PSH Flags</th>\n",
       "      <th>Fwd URG Flags</th>\n",
       "      <th>Bwd URG Flags</th>\n",
       "      <th>Fwd Header Len</th>\n",
       "      <th>Bwd Header Len</th>\n",
       "      <th>Fwd Pkts/s</th>\n",
       "      <th>Bwd Pkts/s</th>\n",
       "      <th>Pkt Len Min</th>\n",
       "      <th>Pkt Len Max</th>\n",
       "      <th>Pkt Len Mean</th>\n",
       "      <th>Pkt Len Std</th>\n",
       "      <th>Pkt Len Var</th>\n",
       "      <th>FIN Flag Cnt</th>\n",
       "      <th>SYN Flag Cnt</th>\n",
       "      <th>RST Flag Cnt</th>\n",
       "      <th>PSH Flag Cnt</th>\n",
       "      <th>ACK Flag Cnt</th>\n",
       "      <th>URG Flag Cnt</th>\n",
       "      <th>CWE Flag Count</th>\n",
       "      <th>ECE Flag Cnt</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <th>Pkt Size Avg</th>\n",
       "      <th>Fwd Seg Size Avg</th>\n",
       "      <th>Bwd Seg Size Avg</th>\n",
       "      <th>Fwd Byts/b Avg</th>\n",
       "      <th>Fwd Pkts/b Avg</th>\n",
       "      <th>Fwd Blk Rate Avg</th>\n",
       "      <th>Bwd Byts/b Avg</th>\n",
       "      <th>Bwd Pkts/b Avg</th>\n",
       "      <th>Bwd Blk Rate Avg</th>\n",
       "      <th>Subflow Fwd Pkts</th>\n",
       "      <th>Subflow Fwd Byts</th>\n",
       "      <th>Subflow Bwd Pkts</th>\n",
       "      <th>Subflow Bwd Byts</th>\n",
       "      <th>Init Fwd Win Byts</th>\n",
       "      <th>Init Bwd Win Byts</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>prot_0</th>\n",
       "      <th>prot_6</th>\n",
       "      <th>prot_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>445</td>\n",
       "      <td>64443</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>373</td>\n",
       "      <td>172</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>70.283711</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>62.753486</td>\n",
       "      <td>8457.086107</td>\n",
       "      <td>139.658303</td>\n",
       "      <td>8.055375e+03</td>\n",
       "      <td>1.105582e+04</td>\n",
       "      <td>21474</td>\n",
       "      <td>3</td>\n",
       "      <td>64403</td>\n",
       "      <td>1.610075e+04</td>\n",
       "      <td>1.073215e+04</td>\n",
       "      <td>21537</td>\n",
       "      <td>3</td>\n",
       "      <td>64398</td>\n",
       "      <td>2.146600e+04</td>\n",
       "      <td>129.201393</td>\n",
       "      <td>21547</td>\n",
       "      <td>21317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>77.587946</td>\n",
       "      <td>62.070357</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>64.198044</td>\n",
       "      <td>4121.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.555556</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>373</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>1527</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1309.757695</td>\n",
       "      <td>1.527000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>1.527000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1309.757695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>5573</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>358.873138</td>\n",
       "      <td>5.573000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5573</td>\n",
       "      <td>5573</td>\n",
       "      <td>5573</td>\n",
       "      <td>5.573000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5573</td>\n",
       "      <td>5573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>358.873138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32738</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>44934</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.509725</td>\n",
       "      <td>4.493400e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>44934</td>\n",
       "      <td>44934</td>\n",
       "      <td>44934</td>\n",
       "      <td>4.493400e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>44934</td>\n",
       "      <td>44934</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>44.509725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>60108569</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>252</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>42.723920</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.654625</td>\n",
       "      <td>0.099819</td>\n",
       "      <td>1.202171e+07</td>\n",
       "      <td>2.677679e+07</td>\n",
       "      <td>59921494</td>\n",
       "      <td>44882</td>\n",
       "      <td>60108569</td>\n",
       "      <td>2.003619e+07</td>\n",
       "      <td>3.454169e+07</td>\n",
       "      <td>59921494</td>\n",
       "      <td>93516</td>\n",
       "      <td>60013670</td>\n",
       "      <td>6.001367e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60013670</td>\n",
       "      <td>60013670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.066546</td>\n",
       "      <td>0.033273</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>67.714286</td>\n",
       "      <td>51.774235</td>\n",
       "      <td>2680.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>257</td>\n",
       "      <td>7010</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>93559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93559</td>\n",
       "      <td>93559</td>\n",
       "      <td>59921494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59921494</td>\n",
       "      <td>59921494</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1417674</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>964</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>11.547005</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>694.094693</td>\n",
       "      <td>4.937665</td>\n",
       "      <td>2.362790e+05</td>\n",
       "      <td>5.785577e+05</td>\n",
       "      <td>1417255</td>\n",
       "      <td>4</td>\n",
       "      <td>397</td>\n",
       "      <td>1.985000e+02</td>\n",
       "      <td>2.269813e+02</td>\n",
       "      <td>359</td>\n",
       "      <td>38</td>\n",
       "      <td>1417670</td>\n",
       "      <td>4.725567e+05</td>\n",
       "      <td>818132.777500</td>\n",
       "      <td>1417255</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>2.116142</td>\n",
       "      <td>2.821523</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>339.887376</td>\n",
       "      <td>115523.428600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.571429</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>964</td>\n",
       "      <td>8192</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>22011</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.863659</td>\n",
       "      <td>2.201100e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22011</td>\n",
       "      <td>22011</td>\n",
       "      <td>22011</td>\n",
       "      <td>2.201100e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22011</td>\n",
       "      <td>22011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>90.863659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32738</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>116030775</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137894</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>3.867692e+07</td>\n",
       "      <td>6.699040e+07</td>\n",
       "      <td>116030772</td>\n",
       "      <td>1</td>\n",
       "      <td>116030773</td>\n",
       "      <td>1.160308e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>116030773</td>\n",
       "      <td>116030773</td>\n",
       "      <td>116030774</td>\n",
       "      <td>1.160308e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116030774</td>\n",
       "      <td>116030774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.381780</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116030772.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116030772</td>\n",
       "      <td>116030772</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8080</td>\n",
       "      <td>505</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3960.396040</td>\n",
       "      <td>5.050000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>5.050000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3960.396040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2052</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1502980</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.330690</td>\n",
       "      <td>1.502980e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1502980</td>\n",
       "      <td>1502980</td>\n",
       "      <td>1502980</td>\n",
       "      <td>1.502980e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1502980</td>\n",
       "      <td>1502980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.330690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "0       0       445          64443             5             4   \n",
       "1      12        80           1527             2             0   \n",
       "2       7        80           5573             2             0   \n",
       "3      12        80          44934             2             0   \n",
       "4       0       443       60108569             4             2   \n",
       "5       4        80        1417674             3             4   \n",
       "6       7        80          22011             2             0   \n",
       "7       3        80      116030775             2             2   \n",
       "8       1      8080            505             2             0   \n",
       "9       2        80        1502980             2             0   \n",
       "\n",
       "   TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "0              373              172              140                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4              148              252               74                0   \n",
       "5               20              964               20                0   \n",
       "6                0                0                0                0   \n",
       "7               16                0                8                8   \n",
       "8                0                0                0                0   \n",
       "9                0                0                0                0   \n",
       "\n",
       "   Fwd Pkt Len Mean  Fwd Pkt Len Std  Bwd Pkt Len Max  Bwd Pkt Len Min  \\\n",
       "0         74.600000        70.283711              133                0   \n",
       "1          0.000000         0.000000                0                0   \n",
       "2          0.000000         0.000000                0                0   \n",
       "3          0.000000         0.000000                0                0   \n",
       "4         37.000000        42.723920              126              126   \n",
       "5          6.666667        11.547005              964                0   \n",
       "6          0.000000         0.000000                0                0   \n",
       "7          8.000000         0.000000                0                0   \n",
       "8          0.000000         0.000000                0                0   \n",
       "9          0.000000         0.000000                0                0   \n",
       "\n",
       "   Bwd Pkt Len Mean  Bwd Pkt Len Std  Flow Byts/s  Flow Pkts/s  Flow IAT Mean  \\\n",
       "0              43.0        62.753486  8457.086107   139.658303   8.055375e+03   \n",
       "1               0.0         0.000000     0.000000  1309.757695   1.527000e+03   \n",
       "2               0.0         0.000000     0.000000   358.873138   5.573000e+03   \n",
       "3               0.0         0.000000     0.000000    44.509725   4.493400e+04   \n",
       "4             126.0         0.000000     6.654625     0.099819   1.202171e+07   \n",
       "5             241.0       482.000000   694.094693     4.937665   2.362790e+05   \n",
       "6               0.0         0.000000     0.000000    90.863659   2.201100e+04   \n",
       "7               0.0         0.000000     0.137894     0.034474   3.867692e+07   \n",
       "8               0.0         0.000000     0.000000  3960.396040   5.050000e+02   \n",
       "9               0.0         0.000000     0.000000     1.330690   1.502980e+06   \n",
       "\n",
       "   Flow IAT Std  Flow IAT Max  Flow IAT Min  Fwd IAT Tot  Fwd IAT Mean  \\\n",
       "0  1.105582e+04         21474             3        64403  1.610075e+04   \n",
       "1  0.000000e+00          1527          1527         1527  1.527000e+03   \n",
       "2  0.000000e+00          5573          5573         5573  5.573000e+03   \n",
       "3  0.000000e+00         44934         44934        44934  4.493400e+04   \n",
       "4  2.677679e+07      59921494         44882     60108569  2.003619e+07   \n",
       "5  5.785577e+05       1417255             4          397  1.985000e+02   \n",
       "6  0.000000e+00         22011         22011        22011  2.201100e+04   \n",
       "7  6.699040e+07     116030772             1    116030773  1.160308e+08   \n",
       "8  0.000000e+00           505           505          505  5.050000e+02   \n",
       "9  0.000000e+00       1502980       1502980      1502980  1.502980e+06   \n",
       "\n",
       "    Fwd IAT Std  Fwd IAT Max  Fwd IAT Min  Bwd IAT Tot  Bwd IAT Mean  \\\n",
       "0  1.073215e+04        21537            3        64398  2.146600e+04   \n",
       "1  0.000000e+00         1527         1527            0  0.000000e+00   \n",
       "2  0.000000e+00         5573         5573            0  0.000000e+00   \n",
       "3  0.000000e+00        44934        44934            0  0.000000e+00   \n",
       "4  3.454169e+07     59921494        93516     60013670  6.001367e+07   \n",
       "5  2.269813e+02          359           38      1417670  4.725567e+05   \n",
       "6  0.000000e+00        22011        22011            0  0.000000e+00   \n",
       "7  0.000000e+00    116030773    116030773    116030774  1.160308e+08   \n",
       "8  0.000000e+00          505          505            0  0.000000e+00   \n",
       "9  0.000000e+00      1502980      1502980            0  0.000000e+00   \n",
       "\n",
       "     Bwd IAT Std  Bwd IAT Max  Bwd IAT Min  Fwd PSH Flags  Bwd PSH Flags  \\\n",
       "0     129.201393        21547        21317              0              0   \n",
       "1       0.000000            0            0              0              0   \n",
       "2       0.000000            0            0              0              0   \n",
       "3       0.000000            0            0              0              0   \n",
       "4       0.000000     60013670     60013670              1              0   \n",
       "5  818132.777500      1417255           18              0              0   \n",
       "6       0.000000            0            0              0              0   \n",
       "7       0.000000    116030774    116030774              1              0   \n",
       "8       0.000000            0            0              0              0   \n",
       "9       0.000000            0            0              0              0   \n",
       "\n",
       "   Fwd URG Flags  Bwd URG Flags  Fwd Header Len  Bwd Header Len   Fwd Pkts/s  \\\n",
       "0              0              0             112              92    77.587946   \n",
       "1              0              0              64               0  1309.757695   \n",
       "2              0              0              40               0   358.873138   \n",
       "3              0              0              64               0    44.509725   \n",
       "4              0              0              80              40     0.066546   \n",
       "5              0              0              72              92     2.116142   \n",
       "6              0              0              40               0    90.863659   \n",
       "7              0              0              64              64     0.017237   \n",
       "8              0              0              40               0  3960.396040   \n",
       "9              0              0              64               0     1.330690   \n",
       "\n",
       "   Bwd Pkts/s  Pkt Len Min  Pkt Len Max  Pkt Len Mean  Pkt Len Std  \\\n",
       "0   62.070357            0          140     54.500000    64.198044   \n",
       "1    0.000000            0            0      0.000000     0.000000   \n",
       "2    0.000000            0            0      0.000000     0.000000   \n",
       "3    0.000000            0            0      0.000000     0.000000   \n",
       "4    0.033273            0          126     67.714286    51.774235   \n",
       "5    2.821523            0          964    123.000000   339.887376   \n",
       "6    0.000000            0            0      0.000000     0.000000   \n",
       "7    0.017237            0            8      4.800000     4.381780   \n",
       "8    0.000000            0            0      0.000000     0.000000   \n",
       "9    0.000000            0            0      0.000000     0.000000   \n",
       "\n",
       "     Pkt Len Var  FIN Flag Cnt  SYN Flag Cnt  RST Flag Cnt  PSH Flag Cnt  \\\n",
       "0    4121.388889             0             0             0             1   \n",
       "1       0.000000             0             0             0             0   \n",
       "2       0.000000             0             0             0             0   \n",
       "3       0.000000             0             0             0             0   \n",
       "4    2680.571429             0             1             0             0   \n",
       "5  115523.428600             0             0             1             1   \n",
       "6       0.000000             0             0             0             0   \n",
       "7      19.200000             0             1             0             0   \n",
       "8       0.000000             0             0             0             0   \n",
       "9       0.000000             0             0             0             0   \n",
       "\n",
       "   ACK Flag Cnt  URG Flag Cnt  CWE Flag Count  ECE Flag Cnt  Down/Up Ratio  \\\n",
       "0             0             0               0             0            0.0   \n",
       "1             1             0               0             0            0.0   \n",
       "2             1             0               0             0            0.0   \n",
       "3             1             0               0             0            0.0   \n",
       "4             1             0               0             0            0.0   \n",
       "5             0             0               0             1            1.0   \n",
       "6             1             0               0             0            0.0   \n",
       "7             1             0               0             0            1.0   \n",
       "8             1             0               0             0            0.0   \n",
       "9             1             0               0             0            0.0   \n",
       "\n",
       "   Pkt Size Avg  Fwd Seg Size Avg  Bwd Seg Size Avg  Fwd Byts/b Avg  \\\n",
       "0     60.555556         74.600000              43.0             0.0   \n",
       "1      0.000000          0.000000               0.0             0.0   \n",
       "2      0.000000          0.000000               0.0             0.0   \n",
       "3      0.000000          0.000000               0.0             0.0   \n",
       "4     79.000000         37.000000             126.0             0.0   \n",
       "5    140.571429          6.666667             241.0             0.0   \n",
       "6      0.000000          0.000000               0.0             0.0   \n",
       "7      6.000000          8.000000               0.0             0.0   \n",
       "8      0.000000          0.000000               0.0             0.0   \n",
       "9      0.000000          0.000000               0.0             0.0   \n",
       "\n",
       "   Fwd Pkts/b Avg  Fwd Blk Rate Avg  Bwd Byts/b Avg  Bwd Pkts/b Avg  \\\n",
       "0             0.0               0.0             0.0             0.0   \n",
       "1             0.0               0.0             0.0             0.0   \n",
       "2             0.0               0.0             0.0             0.0   \n",
       "3             0.0               0.0             0.0             0.0   \n",
       "4             0.0               0.0             0.0             0.0   \n",
       "5             0.0               0.0             0.0             0.0   \n",
       "6             0.0               0.0             0.0             0.0   \n",
       "7             0.0               0.0             0.0             0.0   \n",
       "8             0.0               0.0             0.0             0.0   \n",
       "9             0.0               0.0             0.0             0.0   \n",
       "\n",
       "   Bwd Blk Rate Avg  Subflow Fwd Pkts  Subflow Fwd Byts  Subflow Bwd Pkts  \\\n",
       "0               0.0                 5               373                 4   \n",
       "1               0.0                 2                 0                 0   \n",
       "2               0.0                 2                 0                 0   \n",
       "3               0.0                 2                 0                 0   \n",
       "4               0.0                 4               148                 2   \n",
       "5               0.0                 3                20                 4   \n",
       "6               0.0                 2                 0                 0   \n",
       "7               0.0                 2                16                 2   \n",
       "8               0.0                 2                 0                 0   \n",
       "9               0.0                 2                 0                 0   \n",
       "\n",
       "   Subflow Bwd Byts  Init Fwd Win Byts  Init Bwd Win Byts  Fwd Act Data Pkts  \\\n",
       "0               172               8192                  0                  3   \n",
       "1                 0                225                 -1                  0   \n",
       "2                 0              32738                 -1                  0   \n",
       "3                 0                225                 -1                  0   \n",
       "4               252                257               7010                  1   \n",
       "5               964               8192                211                  1   \n",
       "6                 0              32738                 -1                  0   \n",
       "7                 0                211                219                  1   \n",
       "8                 0               2052                 -1                  0   \n",
       "9                 0                226                 -1                  0   \n",
       "\n",
       "   Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                20          0.0         0.0           0           0   \n",
       "1                32          0.0         0.0           0           0   \n",
       "2                20          0.0         0.0           0           0   \n",
       "3                32          0.0         0.0           0           0   \n",
       "4                20      93559.0         0.0       93559       93559   \n",
       "5                20          0.0         0.0           0           0   \n",
       "6                20          0.0         0.0           0           0   \n",
       "7                32          1.0         0.0           1           1   \n",
       "8                20          0.0         0.0           0           0   \n",
       "9                32          0.0         0.0           0           0   \n",
       "\n",
       "     Idle Mean  Idle Std   Idle Max   Idle Min  day  month  year  dayofweek  \\\n",
       "0          0.0       0.0          0          0   20      2  2018          1   \n",
       "1          0.0       0.0          0          0   16      2  2018          4   \n",
       "2          0.0       0.0          0          0   21      2  2018          2   \n",
       "3          0.0       0.0          0          0   16      2  2018          4   \n",
       "4   59921494.0       0.0   59921494   59921494   20      2  2018          1   \n",
       "5          0.0       0.0          0          0   20      2  2018          1   \n",
       "6          0.0       0.0          0          0   21      2  2018          2   \n",
       "7  116030772.0       0.0  116030772  116030772   15      2  2018          3   \n",
       "8          0.0       0.0          0          0    3      2  2018          5   \n",
       "9          0.0       0.0          0          0   15      2  2018          3   \n",
       "\n",
       "   prot_0  prot_6  prot_17  \n",
       "0       0       1        0  \n",
       "1       0       1        0  \n",
       "2       0       1        0  \n",
       "3       0       1        0  \n",
       "4       0       1        0  \n",
       "5       0       1        0  \n",
       "6       0       1        0  \n",
       "7       0       1        0  \n",
       "8       0       1        0  \n",
       "9       0       1        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "df = pd.read_csv('data/train/0.part')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Debugging\n",
    "\n",
    "The network traffic classification model will be trained using the Amazon SageMaker framework container for XGBoost (https://github.com/aws/sagemaker-xgboost-container). Using XGBoost as a framework provides more flexibility than using it as a built-in algorithm as it enables more advanced scenarios that allow pre-processing and post-processing scripts or any kind of custom logic to be incorporated into your training script.\n",
    "\n",
    "First, we will execute basic training to make sure our training script works as expected and we are able to fit the model successfully, and then we will go through the steps for enabling debugging using Amazon SageMaker Debugger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Training\n",
    "\n",
    "We will execute the training script in local mode while building our model: local mode is a functionality enabled by the Amazon SageMaker Python SDK that allows running the same training code and container that will be used in Amazon SageMaker locally on the notebook instance, in order to speed-up experimentation and quickly fix errors before running training with Amazon SageMaker training.\n",
    "\n",
    "For local mode training, we can re-use the training and validation files downloaded on the notebook instance in the previous steps, as local file inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.05\u001b[39;49;00m)  \u001b[37m# 0.2\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--min_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m6\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--silent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--objective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mmulti:softmax\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m15\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_round\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    model_file = model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    model = pkl.load(\u001b[36mopen\u001b[39;49;00m(model_file, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\r\n",
      "\r\n",
      "    args = parse_args()\r\n",
      "    train_files_path, validation_files_path = args.train, args.validation\r\n",
      "    \r\n",
      "    train_files_list = glob.glob(train_files_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/*.*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(train_files_list)\r\n",
      "    \r\n",
      "    val_files_list = glob.glob(validation_files_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/*.*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(val_files_list)\r\n",
      "    \r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading training dataframe...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_train = pd.concat(\u001b[36mmap\u001b[39;49;00m(pd.read_csv, train_files_list))\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading validation dataframe...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_val = pd.concat(\u001b[36mmap\u001b[39;49;00m(pd.read_csv, val_files_list))\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mData loading completed.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    y = df_train.Target.values\r\n",
      "    X =  df_train.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mTarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values\r\n",
      "    val_y = df_val.Target.values\r\n",
      "    val_X = df_val.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mTarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values\r\n",
      "\r\n",
      "    dtrain = xgboost.DMatrix(X, label=y)\r\n",
      "    dval = xgboost.DMatrix(val_X, label=val_y)\r\n",
      "\r\n",
      "    watchlist = [(dtrain, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), (dval, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\r\n",
      "\r\n",
      "    params = {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.max_depth,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33meta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.eta,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mgamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.gamma,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmin_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.min_child_weight,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msilent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.silent,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.objective,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mnum_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.num_class\r\n",
      "    }\r\n",
      "\r\n",
      "    bst = xgboost.train(\r\n",
      "        params=params,\r\n",
      "        dtrain=dtrain,\r\n",
      "        evals=watchlist,\r\n",
      "        num_boost_round=args.num_round)\r\n",
      "    \r\n",
      "    model_dir = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    pkl.dump(bst, \u001b[36mopen\u001b[39;49;00m(model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_dir/train_xgboost_no_debug.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script parses arguments that are passed when the XGBoost Docker container code invokes the script for execution. These arguments represent the hyperparameters that you specify when strarting the training job plus the location of training and validation data; this behavior, named Script Mode execution, is enabled by a library that is installed in the XGBoost container (sagemaker-containers, https://github.com/aws/sagemaker-containers) and facilitates the development of SageMaker-compatible Docker containers.\n",
    "\n",
    "Then, we load training and validation data and execute XGBoost training with the provided parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our script ready, we can leverage on the XGBoost estimator of the Amazon SageMaker Python SDK to start training locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpbktxhziw_algo-1-srzy9_1 ... \n",
      "\u001b[1BAttaching to tmpbktxhziw_algo-1-srzy9_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker_xgboost_container.training:Invoking user training script.\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Module train_xgboost_no_debug does not provide a setup.py. \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Generating setup.cfg\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Generating MANIFEST.in\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Installing module with the following command:\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Building wheels for collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m   Building wheel for train-xgboost-no-debug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \u001b[?25h  Created wheel for train-xgboost-no-debug: filename=train_xgboost_no_debug-1.0.0-py2.py3-none-any.whl size=8455 sha256=003b47054843e92fd4ecf38cf2fe7b9644d8c5f91744b30e26f31e439305feef\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-wbahui0u/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Successfully built train-xgboost-no-debug\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Installing collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Successfully installed train-xgboost-no-debug-1.0.0\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m INFO:sagemaker-containers:Invoking user script\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"current_host\": \"algo-1-srzy9\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"algo-1-srzy9\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"max_depth\": \"3\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"eta\": \"0.1\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"gamma\": \"6\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"min_child_weight\": \"6\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"silent\": \"0\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"objective\": \"multi:softmax\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"num_class\": \"15\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"num_round\": \"10\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"job_name\": \"nw-traffic-classification-xgb-2020-01-15-17-56-18-176\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"master_hostname\": \"algo-1-srzy9\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-17-56-18-176/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"module_name\": \"train_xgboost_no_debug\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"current_host\": \"algo-1-srzy9\",\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m             \"algo-1-srzy9\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m     \"user_entry_point\": \"train_xgboost_no_debug.py\"\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HOSTS=[\"algo-1-srzy9\"]\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HPS={\"eta\":\"0.1\",\"gamma\":\"6\",\"max_depth\":\"3\",\"min_child_weight\":\"6\",\"num_class\":\"15\",\"num_round\":\"10\",\"objective\":\"multi:softmax\",\"silent\":\"0\"}\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_USER_ENTRY_POINT=train_xgboost_no_debug.py\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-srzy9\",\"hosts\":[\"algo-1-srzy9\"]}\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_CURRENT_HOST=algo-1-srzy9\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_MODULE_NAME=train_xgboost_no_debug\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-17-56-18-176/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-srzy9\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-srzy9\"],\"hyperparameters\":{\"eta\":\"0.1\",\"gamma\":\"6\",\"max_depth\":\"3\",\"min_child_weight\":\"6\",\"num_class\":\"15\",\"num_round\":\"10\",\"objective\":\"multi:softmax\",\"silent\":\"0\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nw-traffic-classification-xgb-2020-01-15-17-56-18-176\",\"log_level\":20,\"master_hostname\":\"algo-1-srzy9\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-17-56-18-176/source/sourcedir.tar.gz\",\"module_name\":\"train_xgboost_no_debug\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-srzy9\",\"hosts\":[\"algo-1-srzy9\"]},\"user_entry_point\":\"train_xgboost_no_debug.py\"}\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.1\",\"--gamma\",\"6\",\"--max_depth\",\"3\",\"--min_child_weight\",\"6\",\"--num_class\",\"15\",\"--num_round\",\"10\",\"--objective\",\"multi:softmax\",\"--silent\",\"0\"]\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_MAX_DEPTH=3\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_ETA=0.1\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_GAMMA=6\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_MIN_CHILD_WEIGHT=6\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_SILENT=0\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_OBJECTIVE=multi:softmax\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_NUM_CLASS=15\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m SM_HP_NUM_ROUND=10\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m /miniconda3/bin/python -m train_xgboost_no_debug --eta 0.1 --gamma 6 --max_depth 3 --min_child_weight 6 --num_class 15 --num_round 10 --objective multi:softmax --silent 0\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m ['/opt/ml/input/data/train/0.part']\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m ['/opt/ml/input/data/validation/0.part']\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Loading training dataframe...\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Loading validation dataframe...\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m Data loading completed.\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [0]\ttrain-merror:0.041751\tvalidation-merror:0.042108\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [1]\ttrain-merror:0.039116\tvalidation-merror:0.039413\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [2]\ttrain-merror:0.039121\tvalidation-merror:0.039262\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [3]\ttrain-merror:0.036609\tvalidation-merror:0.037019\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [4]\ttrain-merror:0.034018\tvalidation-merror:0.035172\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [5]\ttrain-merror:0.035573\tvalidation-merror:0.036755\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [6]\ttrain-merror:0.035342\tvalidation-merror:0.036529\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [7]\ttrain-merror:0.033579\tvalidation-merror:0.034814\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [8]\ttrain-merror:0.036977\tvalidation-merror:0.037528\n",
      "\u001b[36malgo-1-srzy9_1  |\u001b[0m [9]\ttrain-merror:0.033664\tvalidation-merror:0.03455\n",
      "\u001b[36mtmpbktxhziw_algo-1-srzy9_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"3\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"6\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"num_class\": \"15\",\n",
    "    \"num_round\": \"10\"\n",
    "}\n",
    "\n",
    "entry_point='train_xgboost_no_debug.py'\n",
    "source_dir='source_dir/'\n",
    "output_path = 's3://{0}/{1}/output/'.format(bucket_name, prefix)\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "estimator = XGBoost(\n",
    "    base_job_name=\"nw-traffic-classification-xgb\",\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_instance_type=\"local\", # Specifying local as instance type to run local-mode training\n",
    "    train_instance_count=1,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "train_config = 'file://data/train/'\n",
    "val_config = 'file://data/val/'\n",
    "\n",
    "estimator.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure that our code works for inference, we can deploy the trained model locally and execute some inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpfcx_02zi_algo-1-2lmdq_1\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Building wheels for collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Building wheel for train-xgboost-no-debug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m \u001b[?25h  Created wheel for train-xgboost-no-debug: filename=train_xgboost_no_debug-1.0.0-py2.py3-none-any.whl size=8455 sha256=6a33af9768c5e9a34f43ef1a5f3f788bad7b9977471b0624be3a9ab851177201\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-8wueu91e/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully built train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Installing collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully installed train-xgboost-no-debug-1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [39] [INFO] Starting gunicorn 19.10.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [39] [INFO] Listening at: unix:/tmp/gunicorn.sock (39)\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [39] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [42] [INFO] Booting worker with pid: 42\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [43] [INFO] Booting worker with pid: 43\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [46] [INFO] Booting worker with pid: 46\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15 17:57:36 +0000] [48] [INFO] Booting worker with pid: 48\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15:17:57:38:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15:17:57:38:INFO] Installing module with the following command:\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Building wheels for collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Building wheel for train-xgboost-no-debug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m \u001b[?25h  Created wheel for train-xgboost-no-debug: filename=train_xgboost_no_debug-1.0.0-py2.py3-none-any.whl size=8453 sha256=3d13fb3eb8486df35314edcd5f6d0edfdc905bc59079d1084b5268af4543e528\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-plm6167o/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully built train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Installing collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Found existing installation: train-xgboost-no-debug 1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m     Uninstalling train-xgboost-no-debug-1.0.0:\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m       Successfully uninstalled train-xgboost-no-debug-1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully installed train-xgboost-no-debug-1.0.0\n",
      "!\u001b[36malgo-1-2lmdq_1  |\u001b[0m 172.18.0.1 - - [15/Jan/2020:17:57:39 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                            instance_type='local') # Using local-mode deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15:18:13:34:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15:18:13:34:INFO] Installing module with the following command:\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Building wheels for collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Building wheel for train-xgboost-no-debug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m \u001b[?25h  Created wheel for train-xgboost-no-debug: filename=train_xgboost_no_debug-1.0.0-py2.py3-none-any.whl size=8454 sha256=fbfe0a6a059ce350eaa4a2b07b48f8ce122dab08cae5269aa35b0d3fee7a5a4b\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-v9lw3f5w/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully built train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Installing collected packages: train-xgboost-no-debug\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m   Found existing installation: train-xgboost-no-debug 1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m     Uninstalling train-xgboost-no-debug-1.0.0:\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m       Successfully uninstalled train-xgboost-no-debug-1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m Successfully installed train-xgboost-no-debug-1.0.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m [2020-01-15:18:13:35:INFO] Determined delimiter of CSV input is ','\n",
      "4.0\n",
      "\u001b[36malgo-1-2lmdq_1  |\u001b[0m 172.18.0.1 - - [15/Jan/2020:18:13:35 +0000] \"POST /invocations HTTP/1.1\" 200 4 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "# We expect 4 - DDoS attacks-LOIC-HTTP as the predicted class for this instance.\n",
    "test_values = [80,1056736,3,4,20,964,20,0,6.666666667,11.54700538,964,0,241.0,482.0,931.1691850999999,6.6241710320000005,176122.6667,431204.4454,1056315,2,394,197.0,275.77164469999997,392,2,1056733,352244.3333,609743.1115,1056315,24,0,0,0,0,72,92,2.8389304419999997,3.78524059,0,964,123.0,339.8873763,115523.4286,0,0,1,1,0,0,0,1,1.0,140.5714286,6.666666667,241.0,0.0,0.0,0.0,0.0,0.0,0.0,3,20,4,964,8192,211,1,20,0.0,0.0,0,0,0.0,0.0,0,0,20,2,2018,1,0,1,0]\n",
    "result = predictor.predict(test_values)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's gracefully stop the deployed local endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "During training, we have seen that both the train-merror and validation-merror are decreasing, although we don't have details on the accuracy per-class (we will address this later). We have also successfully deployed the model to a local endpoint and executed inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossNotDecreasing\n",
    "\n",
    "Once we are confident our training script is working as expected and there are no major errors preventing its execution, we can enable debugging.\n",
    "\n",
    "During training, we will save the state of the tensors using Amazon SageMaker debugging features, and then analyze debugging outputs with jobs that are run while the training job is executed. For XGBoost, Amazon SageMaker debugging supports saving evaluation metrics, lebels and predictions, feature importances, and SHAP values.\n",
    "\n",
    "First, we need to modify our training script to enable Amazon SageMaker debugging. Note that this is required for the XGBoost framework, whilst for MXNet and Tensorflow debugging works also with no code changes.\n",
    "\n",
    "We created a Hook object which we pass as a callback function when creating a Booster. The Hook object is created by loading a JSON configuration that is available in a specific path in the Docker container (opt/ml/input/config/debughookconfig.json); this file is generated by Amazon SageMaker from the CreateTrainingJob() API call configuration. Note that Amazon SageMaker debugging is highly configurable, you can choose exactly what to save.\n",
    "\n",
    "Let's look at the modified script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mbz2\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtempfile\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36murllib.request\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msmdebug\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SaveConfig\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msmdebug.xgboost\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Hook\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.05\u001b[39;49;00m)  \u001b[37m# 0.2\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--min_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m6\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--silent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--objective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mmulti:softmax\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m15\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_round\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\r\n",
      "\r\n",
      "    args = parse_args()\r\n",
      "    train_files_path, validation_files_path = args.train, args.validation\r\n",
      "    \r\n",
      "    train_files_list = glob.glob(train_files_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/*.*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(train_files_list)\r\n",
      "    \r\n",
      "    val_files_list = glob.glob(validation_files_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/*.*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(val_files_list)\r\n",
      "    \r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading training data...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_train = pd.concat(\u001b[36mmap\u001b[39;49;00m(pd.read_csv, train_files_list))\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading validation data...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_val = pd.concat(\u001b[36mmap\u001b[39;49;00m(pd.read_csv, val_files_list))\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mData loading completed.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    y = df_train.Target.values\r\n",
      "    X =  df_train.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mTarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values\r\n",
      "    val_y = df_val.Target.values\r\n",
      "    val_X = df_val.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mTarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values\r\n",
      "\r\n",
      "    dtrain = xgboost.DMatrix(X, label=y)\r\n",
      "    dval = xgboost.DMatrix(val_X, label=val_y)\r\n",
      "\r\n",
      "    params = {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.max_depth,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33meta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.eta,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mgamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.gamma,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmin_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.min_child_weight,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msilent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.silent,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.objective,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mnum_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.num_class}\r\n",
      "\r\n",
      "    hook = Hook.create_from_json_file()\r\n",
      "    hook.train_data = dtrain\r\n",
      "    hook.validation_data = dval\r\n",
      "    \r\n",
      "    watchlist = [(dtrain, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), (dval, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\r\n",
      "\r\n",
      "    bst = xgboost.train(\r\n",
      "        params=params,\r\n",
      "        dtrain=dtrain,\r\n",
      "        evals=watchlist,\r\n",
      "        num_boost_round=args.num_round,\r\n",
      "        callbacks=[hook])\r\n",
      "    \r\n",
      "    model_dir = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    pkl.dump(bst, \u001b[36mopen\u001b[39;49;00m(model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_dir/train_xgboost.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified script allows to **capture tensors** and **save to Amazon S3**, but doing this will not cause any debug analysis to run. In order to analyze debug outputs we need to configure the XGBoost estimator to define **a collection of rules that will be run while the training job is executed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are enabling a built-in (1P) debug rule named **LossNotDecreasing** which checks if the loss is not decreasing across step. In this scenario, we have chosen to run this rule at every step on the validation-merror metric values: this means that the new merror values must always go down at each step.\n",
    "\n",
    "When the estimator fit() method is called, Amazon SageMaker will start two jobs: a **Training Job**, where we also capture and save tensors, and a debug **Processing Job** (powered by **Amazon SageMaker Processing Jobs**), which will run in parallel and analyze tensor data to check if the rule conditions are met.\n",
    "\n",
    "Note that we are passing the **Wait=False** parameter to the fit() method to avoid waiting for the training job to  complete and just fire and forget the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.debugger import Rule, rule_configs, DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"10\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"1\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"num_class\": \"15\",\n",
    "    \"num_round\": \"20\"\n",
    "}\n",
    "\n",
    "entry_point='train_xgboost.py'\n",
    "source_dir='source_dir/'\n",
    "output_path = 's3://{0}/{1}/output/'.format(bucket_name, prefix)\n",
    "debugger_output_path = 's3://{0}/{1}/output/debug'.format(bucket_name, prefix) # Path where we save debug outputs\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "hook_config = DebuggerHookConfig(\n",
    "    s3_output_path=debugger_output_path,\n",
    "    hook_parameters={\n",
    "        \"save_interval\": \"1\"\n",
    "    },\n",
    "    collection_configs=[\n",
    "        CollectionConfig(\"hyperparameters\"),\n",
    "        CollectionConfig(\"metrics\"),\n",
    "        CollectionConfig(\"predictions\"),\n",
    "        CollectionConfig(\"labels\"),\n",
    "        CollectionConfig(\"feature_importance\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "estimator = XGBoost(\n",
    "    base_job_name=\"nw-traffic-classification-xgb\",\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_instance_type=\"ml.m5.4xlarge\",\n",
    "    train_instance_count=1,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role,\n",
    "    \n",
    "    # Initialize your hook.\n",
    "    debugger_hook_config=hook_config,\n",
    "    \n",
    "    # Initialize your rules. These will read data for analyses from the path specified\n",
    "    # for the hook\n",
    "    rules=[Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                         rule_parameters={\n",
    "                             # Rule does not use the default losses collection,\n",
    "                             # but uses a regex to look for specific tensor values\n",
    "                             \"use_losses_collection\": \"False\",\n",
    "                             \"tensor_regex\": \"validation-merror\",\n",
    "                             # Num steps is used to specify when to evaluate this rule (every num_steps)\n",
    "                             \"num_steps\" : \"1\"}\n",
    "                         )]\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/data/train/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/data/val/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "\n",
    "estimator.fit({'train': train_config, 'validation': val_config }, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training job has started, we can check its debug configuration and status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Hook configuration: \n",
      "{'S3OutputPath': 's3://sagemaker-us-east-1-835319576252/aim362/output/debug', 'HookParameters': {'save_interval': '1'}, 'CollectionConfigurations': [{'CollectionName': 'predictions'}, {'CollectionName': 'losses', 'CollectionParameters': {'save_interval': '500'}}, {'CollectionName': 'hyperparameters'}, {'CollectionName': 'feature_importance'}, {'CollectionName': 'metrics'}, {'CollectionName': 'labels'}]}\n",
      "\n",
      "Debug rules configuration: \n",
      "[{'RuleConfigurationName': 'LossNotDecreasing', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'num_steps': '1', 'rule_to_invoke': 'LossNotDecreasing', 'tensor_regex': 'validation-merror', 'use_losses_collection': 'False'}}]\n",
      "\n",
      "Training job status\n",
      "InProgress\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "print('Debug Hook configuration: ')\n",
    "print(description['DebugHookConfig'])\n",
    "print()\n",
    "print('Debug rules configuration: ')\n",
    "print(description['DebugRuleConfigurations'])\n",
    "print()\n",
    "print('Training job status')\n",
    "print(description['TrainingJobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/aim362/output/debug\n"
     ]
    }
   ],
   "source": [
    "print(debugger_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get all the logs for the training job being executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-15 18:20:09 Starting - Preparing the instances for training\n",
      "2020-01-15 18:20:09 Downloading - Downloading input data\n",
      "2020-01-15 18:20:09 Training - Training image download completed. Training in progress.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train_xgboost does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-xgboost\n",
      "  Building wheel for train-xgboost (setup.py): started\n",
      "  Building wheel for train-xgboost (setup.py): finished with status 'done'\n",
      "  Created wheel for train-xgboost: filename=train_xgboost-1.0.0-py2.py3-none-any.whl size=8212 sha256=ccd87ff273aedee380c2a0a5615d62d95bcf6733fd10f382b430d00d213ec57e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vkqyej23/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train-xgboost\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-xgboost\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-xgboost-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"silent\": \"0\",\n",
      "        \"num_class\": \"15\",\n",
      "        \"max_depth\": \"10\",\n",
      "        \"objective\": \"multi:softmax\",\n",
      "        \"eta\": \"0.2\",\n",
      "        \"num_round\": \"20\",\n",
      "        \"gamma\": \"1\",\n",
      "        \"min_child_weight\": \"6\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"nw-traffic-classification-xgb-2020-01-15-18-16-02-812\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-18-16-02-812/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_xgboost\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_xgboost.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"1\",\"max_depth\":\"10\",\"min_child_weight\":\"6\",\"num_class\":\"15\",\"num_round\":\"20\",\"objective\":\"multi:softmax\",\"silent\":\"0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_xgboost.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_xgboost\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-18-16-02-812/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"1\",\"max_depth\":\"10\",\"min_child_weight\":\"6\",\"num_class\":\"15\",\"num_round\":\"20\",\"objective\":\"multi:softmax\",\"silent\":\"0\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nw-traffic-classification-xgb-2020-01-15-18-16-02-812\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/aim362/code/nw-traffic-classification-xgb-2020-01-15-18-16-02-812/source/sourcedir.tar.gz\",\"module_name\":\"train_xgboost\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_xgboost.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"1\",\"--max_depth\",\"10\",\"--min_child_weight\",\"6\",\"--num_class\",\"15\",\"--num_round\",\"20\",\"--objective\",\"multi:softmax\",\"--silent\",\"0\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_SILENT=0\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CLASS=15\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=10\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=multi:softmax\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=20\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=1\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train_xgboost --eta 0.2 --gamma 1 --max_depth 10 --min_child_weight 6 --num_class 15 --num_round 20 --objective multi:softmax --silent 0\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/train/1.part', '/opt/ml/input/data/train/9.part', '/opt/ml/input/data/train/3.part', '/opt/ml/input/data/train/5.part', '/opt/ml/input/data/train/4.part', '/opt/ml/input/data/train/7.part', '/opt/ml/input/data/train/0.part', '/opt/ml/input/data/train/8.part', '/opt/ml/input/data/train/2.part', '/opt/ml/input/data/train/6.part']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, we can check the status of the rule execution job as follows. Note that this requires some time, so you might be interested in looking at the SageMaker Debugger documentation while this runs: https://github.com/awslabs/sagemaker-debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RuleConfigurationName': 'LossNotDecreasing', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--lossnotdecreasing-cea60431', 'RuleEvaluationStatus': 'IssuesFound', 'StatusDetails': 'RuleEvaluationConditionMet: Evaluation of the rule LossNotDecreasing at step 7 resulted in the condition being met\\n', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 22, 11, 503000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "iterate = True\n",
    "while(iterate):\n",
    "    description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "    eval_status = description['DebugRuleEvaluationStatuses'][0]\n",
    "    print(eval_status)\n",
    "    if eval_status['RuleEvaluationStatus'] != 'InProgress':\n",
    "        iterate = False\n",
    "    else:\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule execution job raised an error since the rule evaluation condition is met. Let's review the configuration and logs of the rule execution job, executed by Amazon SageMaker Processing Jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nw-traffic-classification--lossnotdecreasing-cea60431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'Tensors',\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/aim362/output/debug/nw-traffic-classification-xgb-2020-01-15-18-16-02-812/debug-output',\n",
       "    'LocalPath': '/opt/ml/processing/input/tensors',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'RuleOutput',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/aim362/output/nw-traffic-classification-xgb-2020-01-15-18-16-02-812/rule-output',\n",
       "     'LocalPath': '/opt/ml/processing/output/rule',\n",
       "     'S3UploadMode': 'EndOfJob'}}]},\n",
       " 'ProcessingJobName': 'nw-traffic-classification--LossNotDecreasing-cea60431',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.t3.medium',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest'},\n",
       " 'Environment': {'num_steps': '1',\n",
       "  'rule_to_invoke': 'LossNotDecreasing',\n",
       "  'tensor_regex': 'validation-merror',\n",
       "  'use_losses_collection': 'False'},\n",
       " 'NetworkConfig': {'EnableNetworkIsolation': False},\n",
       " 'RoleArn': 'arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--lossnotdecreasing-cea60431',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ExitMessage': 'RuleEvaluationConditionMet: Evaluation of the rule LossNotDecreasing at step 7 resulted in the condition being met\\n',\n",
       " 'ProcessingEndTime': datetime.datetime(2020, 1, 15, 18, 21, 55, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2020, 1, 15, 18, 17, 54, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 21, 55, 681000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2020, 1, 15, 18, 16, 5, 287000, tzinfo=tzlocal()),\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:training-job/nw-traffic-classification-xgb-2020-01-15-18-16-02-812',\n",
       " 'ResponseMetadata': {'RequestId': '1aeefe3f-632c-4aad-87db-52c7cdcc3c34',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1aeefe3f-632c-4aad-87db-52c7cdcc3c34',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1831',\n",
       "   'date': 'Wed, 15 Jan 2020 18:27:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_job_arn = eval_status['RuleEvaluationJobArn']\n",
    "processing_job_name = processing_job_arn[processing_job_arn.rfind('/') + 1 :]\n",
    "print(processing_job_name)\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "descr = client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2020-01-15 18:21:46.034 ip-10-2-233-251.ec2.internal:1 INFO local_trial.py:35] Loading trial base_trial at path /opt/ml/processing/input/tensors\u001b[0m\n",
      "\u001b[34mNo environment variable found with name \"base_trial\". Will use default param value if present\u001b[0m\n",
      "\u001b[34mNo environment variable found with name \"collection_names\". Will use default param value if present\u001b[0m\n",
      "\u001b[34mNo environment variable found with name \"diff_percent\". Will use default param value if present\u001b[0m\n",
      "\u001b[34mNo environment variable found with name \"mode\". Will use default param value if present\u001b[0m\n",
      "\u001b[34m[2020-01-15 18:21:46.147 ip-10-2-233-251.ec2.internal:1 INFO loss_decrease.py:76] LossNotDecreasing rule created with num_steps: 1, diff_percent: 0.0, mode: GLOBAL, tensor_regex: validation-merror, collection_names: \u001b[0m\n",
      "\u001b[34m[2020-01-15 18:21:46.147 ip-10-2-233-251.ec2.internal:1 INFO rule_invoker.py:10] Started execution of rule LossNotDecreasing at step 0\u001b[0m\n",
      "\u001b[34m[2020-01-15 18:21:46.160 ip-10-2-233-251.ec2.internal:1 INFO loss_decrease.py:194] 1 loss is not decreasing over the last 1 steps at step 7\u001b[0m\n",
      "\u001b[34mException during rule evaluation: RuleEvaluationConditionMet: Evaluation of the rule LossNotDecreasing at step 7 resulted in the condition being met\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_processing_job(descr['ProcessingJobName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "We can see that the condition is being met at step 7 when validation-merror is not decreasing. When this happens, we might be interested in stopping training earlier. You can also leverage on Amazon CloudWatch Events to detect the rule condition met event and take specific actions automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging - Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example of using a first party (1P) rule provided by Amazon SageMaker debugging, let us again train and use a 1P rule `Confusion` to monitor the training job in realtime.\n",
    "\n",
    "During training, `Confusion` Rule job will monitor whether you are running into a situation where the ratio of on-diagonal and off-diagonal values in the confusion matrix is not within a specified range. In other words, this rule evaluates the goodness of a confusion matrix for a classification problem. It creates a matrix of size `category_no` $\\times$ `category_no` and populates it with data coming from (`y`, `y_hat`) pairs. For each (`y`, `y_hat`) pairs the count in `confusion[y][y_hat]` is  incremented by 1. Once the matrix is fully populated, the ratio of data on- and off-diagonal will be evaluated according to:\n",
    "\n",
    "- For elements on the diagonal:\n",
    "\n",
    "$$ \\frac{ \\text{confusion}_{ii} }{ \\sum_j \\text{confusion}_{jj} } \\geq \\text{min_diag} $$\n",
    "\n",
    "- For elements off the diagonal:\n",
    "\n",
    "$$ \\frac{ \\text{confusion}_{ji} }{ \\sum_j \\text{confusion}_{ji} } \\leq \\text{max_off_diag} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that in this case we are setting the `start_step` and `end_step` rule parameters, to make sure the rule is evaluated only during the latest steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.debugger import Rule, rule_configs, DebuggerHookConfig\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"10\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"1\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"num_class\": \"15\",\n",
    "    \"num_round\": \"20\"\n",
    "}\n",
    "\n",
    "entry_point='train_xgboost.py'\n",
    "source_dir='source_dir/'\n",
    "output_path = 's3://{0}/{1}/output/'.format(bucket_name, prefix)\n",
    "debugger_output_path = 's3://{0}/{1}/output/debug'.format(bucket_name, prefix)\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "hook_config = DebuggerHookConfig(\n",
    "    s3_output_path=debugger_output_path,\n",
    "    hook_parameters={\n",
    "        \"save_interval\": \"1\"\n",
    "    },\n",
    "    collection_configs=[\n",
    "        CollectionConfig(\"hyperparameters\"),\n",
    "        CollectionConfig(\"metrics\"),\n",
    "        CollectionConfig(\"predictions\"),\n",
    "        CollectionConfig(\"labels\"),\n",
    "        CollectionConfig(\"feature_importance\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "estimator = XGBoost(\n",
    "    base_job_name=\"nw-traffic-classification-xgb\",\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_instance_type=\"ml.m5.4xlarge\",\n",
    "    train_instance_count=1,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role,\n",
    "    \n",
    "    # Initialize your hook.\n",
    "    debugger_hook_config=hook_config,\n",
    "    \n",
    "    # Initialize your rules. These will read data for analyses from the path specified\n",
    "    # for the hook\n",
    "    rules=[Rule.sagemaker(rule_configs.confusion(),\n",
    "                             rule_parameters={\n",
    "                                 \"category_no\": \"15\",\n",
    "                                 \"min_diag\": \"0.7\",\n",
    "                                 \"max_off_diag\": \"0.3\",\n",
    "                                 \"start_step\": \"17\",\n",
    "                                 \"end_step\": \"19\"}\n",
    "                         )]\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/data/train/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/data/val/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "\n",
    "estimator.fit({'train': train_config, 'validation': val_config }, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agan, let's review the training job status, configuration and logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Hook configuration: \n",
      "{'S3OutputPath': 's3://sagemaker-us-east-1-835319576252/aim362/output/debug', 'HookParameters': {'save_interval': '1'}, 'CollectionConfigurations': [{'CollectionName': 'predictions'}, {'CollectionName': 'hyperparameters'}, {'CollectionName': 'feature_importance'}, {'CollectionName': 'metrics'}, {'CollectionName': 'labels'}]}\n",
      "\n",
      "Debug rules configuration: \n",
      "[{'RuleConfigurationName': 'Confusion', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'category_no': '15', 'end_step': '19', 'max_off_diag': '0.3', 'min_diag': '0.7', 'rule_to_invoke': 'Confusion', 'start_step': '17'}}]\n",
      "\n",
      "Training job status\n",
      "InProgress\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "print('Debug Hook configuration: ')\n",
    "print(description['DebugHookConfig'])\n",
    "print()\n",
    "print('Debug rules configuration: ')\n",
    "print(description['DebugRuleConfigurations'])\n",
    "print()\n",
    "print('Training job status')\n",
    "print(description['TrainingJobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-15 18:28:49 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can wait for the rule execution to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 28, 49, 148000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 29, 31, 43000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 30, 31, 829000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 31, 32, 608000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 32, 33, 328000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 33, 34, 90000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 33, 54, 344000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 35, 35, 830000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 36, 36, 826000, tzinfo=tzlocal())}\n",
      "{'RuleConfigurationName': 'Confusion', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/nw-traffic-classification--confusion-23762dd9', 'RuleEvaluationStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 1, 15, 18, 37, 37, 693000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "iterate = True\n",
    "while(iterate):\n",
    "    description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "    eval_status = description['DebugRuleEvaluationStatuses'][0]\n",
    "    print(eval_status)\n",
    "    if eval_status['RuleEvaluationStatus'] != 'InProgress':\n",
    "        iterate = False\n",
    "    else:\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review the rule execution job, executed by Amazon SageMaker Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_arn = eval_status['RuleEvaluationJobArn']\n",
    "processing_job_name = processing_job_arn[processing_job_arn.rfind('/') + 1 :]\n",
    "print(processing_job_name)\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "descr = client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.logs_for_processing_job(descr['ProcessingJobName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make sure the training job is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "iterate = True\n",
    "while(iterate):\n",
    "    description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "    training_job_status = description['TrainingJobStatus']\n",
    "    print(training_job_status)\n",
    "    if training_job_status != 'InProgress':\n",
    "        iterate = False\n",
    "    else:\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "We can see that the condition is being met and this gives evidences that our confusion matrix is not matching our thresholds.\n",
    "Let's review the confusion matrix by analyzing the debug outputs in next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Debug Outputs\n",
    "\n",
    "In this section we will see how you can use the SDK to manually analyze debug outputs.\n",
    "\n",
    "First thing is creating a trial, which is the construct that allows accessing to tensors for a single training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "s3_output_path = description[\"DebugHookConfig\"][\"S3OutputPath\"] + '/' + estimator.latest_training_job.name + '/debug-output/'\n",
    "print(s3_output_path)\n",
    "trial = create_trial(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the list of all the tensors that were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a specific tensor, we can ask at which steps we have data for the tensor. In this case, we have data for all steps since the frequency was set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor(\"validation-merror\").steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the value of a specific tensor for a specific step as numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor(\"train-merror\").value(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a simple function that visualizes the training and validation errors as the training progresses. We expect each training errors to get smaller over time, as the system converges to a good solution. Now, remember that this is an interactive analysis - we are showing these tensors to give an idea of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a function that, for the given tensor name, walks through all \n",
    "# the iterations for which we have data and fetches the value.\n",
    "# Returns the set of steps and the values\n",
    "def get_data(trial, tname):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\"train-merror\", \"validation-merror\"]\n",
    "for metric in metrics_to_plot:\n",
    "    steps, data = get_data(trial, metric)\n",
    "    plt.plot(steps, data, label=metric)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the feature importances as determined by xgboost.get_fscore(). Note that feature importances with zero values are not included here (which means that those features were not used in any split conditions).\n",
    "\n",
    "For more information on the metrics related to feature importance in XGBoost, please visit: https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7\n",
    "\n",
    "`weight` is the number of times a feature is used to split the data across all trees <br />\n",
    "`gain` represents fractional contribution of each feature to the model based on the total gain of this feature's splits. Higher percentage means a more important predictive feature <br />\n",
    "`cover` is a metric of the number of observation related to this feature <br />\n",
    "`total_gain` is the total gain across all splits the feature is used in <br />\n",
    "`total_cover` is the total coverage across all splits the feature is used in <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "def plot_feature_importance(trial, collection_name, step, metric):\n",
    "    feature_importance_tensors = trial.collection(collection_name).tensor_names\n",
    "\n",
    "    feature_names = []\n",
    "    feature_values = []\n",
    "    \n",
    "    plt.subplots(figsize=(18,7))\n",
    "    \n",
    "    for tensor_name in feature_importance_tensors:\n",
    "        if tensor_name.find('/' + metric) >= 0:\n",
    "            index = tensor_name.rfind('/')\n",
    "            feature_name = tensor_name[index+1:]\n",
    "            feature_names.append(feature_name)\n",
    "            tensor = trial.tensor(tensor_name)\n",
    "            value_at_step = tensor.value(step)[0]\n",
    "            feature_values.append(value_at_step)\n",
    "\n",
    "    pos = range(len(feature_values))\n",
    "    plt.bar(pos, feature_values, color='g')\n",
    "    plt.xlabel('Features', fontsize=16)\n",
    "    plt.ylabel('Feature Importance ({0})'.format(metric), fontsize=16)\n",
    "    plt.xticks(pos, feature_names)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(trial, \"feature_importance\", 19, \"gain\")\n",
    "plot_feature_importance(trial, \"feature_importance\", 19, \"cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Finally, since we were logging labels and predictions, we can visualize the confusion matrix of the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "step = 19\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    trial.tensor('labels').value(step),\n",
    "    trial.tensor('predictions').value(step)\n",
    ")\n",
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(normalized_cm, ax=ax, annot=cm, fmt='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move to <a href=\"../02_deploy_and_monitor/deploy_and_monitor.ipynb\">Deploy and Monitor</a> to see how to deploy this model and monitor its inference performance over time using Amazon SageMaker Model Monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "A Realistic Cyber Defense Dataset (CSE-CIC-IDS2018) https://registry.opendata.aws/cse-cic-ids2018/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
